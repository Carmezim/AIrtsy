{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "IMAGE_W = 800 \n",
    "IMAGE_H = 600 \n",
    "CONTENT_IMG =  './images/raw.jpg'\n",
    "STYLE_IMG = './images/StarryNight.jpg'\n",
    "OUTOUT_DIR = './results'\n",
    "OUTPUT_IMG = 'results.png'\n",
    "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
    "INI_NOISE_RATIO = 0.7\n",
    "STYLE_STRENGTH = 500\n",
    "ITERATION = 5000\n",
    "\n",
    "CONTENT_LAYERS =[('conv4_2',1.)]\n",
    "# To obtain softer features increase higher layers weight and decrease lower layers weight.\n",
    "# For harder features do the opposite.\n",
    "STYLE_LAYERS=[('conv1_1',1.),('conv2_1',1.5),('conv3_1',2.),('conv4_1',2.5),('conv5_1',3.)]\n",
    "\n",
    "\n",
    "MEAN_VALUES = np.array([123, 117, 104]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_net(ntype, nin, nwb=None):\n",
    "  if ntype == 'conv':\n",
    "    return tf.nn.relu(tf.nn.conv2d(nin, nwb[0], strides=[1, 1, 1, 1], padding='SAME')+ nwb[1])\n",
    "  elif ntype == 'pool':\n",
    "    return tf.nn.avg_pool(nin, ksize=[1, 2, 2, 1],\n",
    "                  strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Weights and bias from the VGG model for a given layer.\n",
    "def get_weight_bias(vgg_layers, i,):\n",
    "  weights = vgg_layers[i][0][0][0][0][0]\n",
    "  weights = tf.constant(weights)\n",
    "  bias = vgg_layers[i][0][0][0][0][1]\n",
    "  bias = tf.constant(np.reshape(bias, (bias.size)))\n",
    "  return weights, bias\n",
    "\n",
    "def build_vgg19(path):\n",
    "    \"\"\"\n",
    "    Detailed configuration of the VGG model:\n",
    "        0 is conv1_1 (3, 3, 3, 64)\n",
    "        1 is relu\n",
    "        2 is conv1_2 (3, 3, 64, 64)\n",
    "        3 is relu    \n",
    "        4 is maxpool\n",
    "        5 is conv2_1 (3, 3, 64, 128)\n",
    "        6 is relu\n",
    "        7 is conv2_2 (3, 3, 128, 128)\n",
    "        8 is relu\n",
    "        9 is maxpool\n",
    "        10 is conv3_1 (3, 3, 128, 256)\n",
    "        11 is relu\n",
    "        12 is conv3_2 (3, 3, 256, 256)\n",
    "        13 is relu\n",
    "        14 is conv3_3 (3, 3, 256, 256)\n",
    "        15 is relu\n",
    "        16 is conv3_4 (3, 3, 256, 256)\n",
    "        17 is relu\n",
    "        18 is maxpool\n",
    "        19 is conv4_1 (3, 3, 256, 512)\n",
    "        20 is relu\n",
    "        21 is conv4_2 (3, 3, 512, 512)\n",
    "        22 is relu\n",
    "        23 is conv4_3 (3, 3, 512, 512)\n",
    "        24 is relu\n",
    "        25 is conv4_4 (3, 3, 512, 512)\n",
    "        26 is relu\n",
    "        27 is maxpool\n",
    "        28 is conv5_1 (3, 3, 512, 512)\n",
    "        29 is relu\n",
    "        30 is conv5_2 (3, 3, 512, 512)\n",
    "        31 is relu\n",
    "        32 is conv5_3 (3, 3, 512, 512)\n",
    "        33 is relu\n",
    "        34 is conv5_4 (3, 3, 512, 512)\n",
    "        35 is relu\n",
    "        36 is maxpool\n",
    "        37 is fullyconnected (7, 7, 512, 4096)\n",
    "        38 is relu\n",
    "        39 is fullyconnected (1, 1, 4096, 4096)\n",
    "        40 is relu\n",
    "        41 is fullyconnected (1, 1, 4096, 1000)\n",
    "        42 is softmax\n",
    "    \"\"\"\n",
    "  net = {}\n",
    "  vgg_rawnet = scipy.io.loadmat(path)\n",
    "  vgg_layers = vgg_rawnet['layers'][0]\n",
    "  net['input'] = tf.Variable(np.zeros((1, IMAGE_H, IMAGE_W, 3)).astype('float32'))\n",
    "  net['conv1_1'] = build_net('conv',net['input'],get_weight_bias(vgg_layers,0))\n",
    "  net['conv1_2'] = build_net('conv',net['conv1_1'],get_weight_bias(vgg_layers,2))\n",
    "  net['pool1']   = build_net('pool',net['conv1_2'])\n",
    "  net['conv2_1'] = build_net('conv',net['pool1'],get_weight_bias(vgg_layers,5))\n",
    "  net['conv2_2'] = build_net('conv',net['conv2_1'],get_weight_bias(vgg_layers,7))\n",
    "  net['pool2']   = build_net('pool',net['conv2_2'])\n",
    "  net['conv3_1'] = build_net('conv',net['pool2'],get_weight_bias(vgg_layers,10))\n",
    "  net['conv3_2'] = build_net('conv',net['conv3_1'],get_weight_bias(vgg_layers,12))\n",
    "  net['conv3_3'] = build_net('conv',net['conv3_2'],get_weight_bias(vgg_layers,14))\n",
    "  net['conv3_4'] = build_net('conv',net['conv3_3'],get_weight_bias(vgg_layers,16))\n",
    "  net['pool3']   = build_net('pool',net['conv3_4'])\n",
    "  net['conv4_1'] = build_net('conv',net['pool3'],get_weight_bias(vgg_layers,19))\n",
    "  net['conv4_2'] = build_net('conv',net['conv4_1'],get_weight_bias(vgg_layers,21))\n",
    "  net['conv4_3'] = build_net('conv',net['conv4_2'],get_weight_bias(vgg_layers,23))\n",
    "  net['conv4_4'] = build_net('conv',net['conv4_3'],get_weight_bias(vgg_layers,25))\n",
    "  net['pool4']   = build_net('pool',net['conv4_4'])\n",
    "  net['conv5_1'] = build_net('conv',net['pool4'],get_weight_bias(vgg_layers,28))\n",
    "  net['conv5_2'] = build_net('conv',net['conv5_1'],get_weight_bias(vgg_layers,30))\n",
    "  net['conv5_3'] = build_net('conv',net['conv5_2'],get_weight_bias(vgg_layers,32))\n",
    "  net['conv5_4'] = build_net('conv',net['conv5_3'],get_weight_bias(vgg_layers,34))\n",
    "  net['pool5']   = build_net('pool',net['conv5_4'])\n",
    "  return net\n",
    "\n",
    "def build_content_loss(p, x):\n",
    "  M = p.shape[1]*p.shape[2]\n",
    "  N = p.shape[3]\n",
    "  loss = (1./(2* N**0.5 * M**0.5 )) * tf.reduce_sum(tf.pow((x - p),2))  \n",
    "  return loss\n",
    "\n",
    "\n",
    "def gram_matrix(x, area, depth):\n",
    "  x1 = tf.reshape(x,(area,depth))\n",
    "  g = tf.matmul(tf.transpose(x1), x1)\n",
    "  return g\n",
    "\n",
    "def gram_matrix_val(x, area, depth):\n",
    "  x1 = x.reshape(area,depth)\n",
    "  g = np.dot(x1.T, x1)\n",
    "  return g\n",
    "\n",
    "def build_style_loss(a, x):\n",
    "  # M is the height times the width of the feature map.\n",
    "  M = a.shape[1]*a.shape[2]\n",
    "  # N is the number of filters.    \n",
    "  N = a.shape[3]\n",
    "  # A is the style representation of the original image.  \n",
    "  A = gram_matrix_val(a, M, N )\n",
    "  # G is the style representation of the generated image.\n",
    "  G = gram_matrix(x, M, N )\n",
    "  loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A),2))\n",
    "  return loss\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "  image = scipy.misc.imread(path)\n",
    "  # Resize the image for convnet input.\n",
    "  image = image[np.newaxis,:IMAGE_H,:IMAGE_W,:]\n",
    "  # Input to VGG model expects the mean to be subtracted.\n",
    "  image = image - MEAN_VALUES\n",
    "  return image\n",
    "\n",
    "def write_image(path, image):\n",
    "  image = image + MEAN_VALUES\n",
    "  image = image[0]\n",
    "  image = np.clip(image, 0, 255).astype('uint8')\n",
    "  scipy.misc.imsave(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = build_vgg19(VGG_MODEL)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "# Generates noise image from content image. \n",
    "noise_img = np.random.uniform(-20, 20, (1, IMAGE_H, IMAGE_W, 3)).astype('float32')\n",
    "\n",
    "# Load content image.\n",
    "content_img = read_image(CONTENT_IMG)\n",
    "imshow(content_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load style image.\n",
    "style_img = read_image(STYLE_IMG)\n",
    "imshow(style_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Content Loss.  \n",
    "sess.run([net['input'].assign(content_img)])\n",
    "cost_content = sum(map(lambda l,: l[1]*build_content_loss(sess.run(net[l[0]]) ,  net[l[0]])\n",
    ", CONTENT_LAYERS))\n",
    "\n",
    "# Style Loss.  \n",
    "sess.run([net['input'].assign(style_img)])\n",
    "cost_style = sum(map(lambda l: l[1]*build_style_loss(sess.run(net[l[0]]) ,  net[l[0]])\n",
    ", STYLE_LAYERS))\n",
    "\n",
    "# Equation 7 (see paper).  \n",
    "cost_total = cost_content + STYLE_STRENGTH * cost_style\n",
    "# Minimizes white noise image distance from content image and the painting style image.\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "# Minize total loss.\n",
    "train = optimizer.minimize(cost_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())\n",
    "  sess.run(net['input'].assign( INI_NOISE_RATIO* noise_img + (1.-INI_NOISE_RATIO) * content_img))\n",
    "\n",
    "  if not os.path.exists(OUTOUT_DIR):\n",
    "      os.mkdir(OUTOUT_DIR)\n",
    "\n",
    "  for i in range(ITERATION):\n",
    "    sess.run(train)\n",
    "    if i%100 ==0:\n",
    "      result_img = sess.run(net['input'])\n",
    "      print('Iteration %d' % (i))\n",
    "      print('Sum: ', sess.run(tf.reduce_sum(result_img)))  \n",
    "      print('Cost: ', sess.run(cost_total))\n",
    "      write_image(os.path.join(OUTOUT_DIR,'%s.png'%(str(i).zfill(4))),result_img)\n",
    "  \n",
    "  write_image(os.path.join(OUTOUT_DIR,OUTPUT_IMG),result_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
